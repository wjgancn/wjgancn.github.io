<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Weijie Gan</title>
  
  <meta name="author"   content="Weijie Gan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                   <name>Weijie Gan 甘伟捷</name>
                </p>
                <p> 
                    I am a 4th year PhD student in <a href="https://cigroup.wustl.edu">Computational Imaging Group (CIG)</a> from Computer Science and Engineering Department at <a href="https://wustl.edu">Washington University in St. Louis (WashU)</a>, supervised by <a href="https://engineering.wustl.edu/faculty/Ulugbek-Kamilov.html">Prof. Ulugbek Kamilov</a> and <a href="https://www.mir.wustl.edu/employees/hongyu-an/">Prof. Hongyu An</a>. Before starting my PhD, I received the M.Sc. degree in Computer Science, in 2020, also from WashU, and the B.Sc. degree in Automation from <a href="https://www.scut.edu.cn/en/">South China University of Technology</a>, Guangzhou, China, in 2018.
                </p>
                <p>
                  My research focuses on algorithms designs and theoretical analysis for deep learning-based computational imaging. My research topics include self-supervised learning, image reconstruction, image registration, and correction of physical model uncertainty. My work has been shown to deliver real-world impact for various imaging applications, including MRI, PET, deconvolution, and ptychography.
                </p>
                <p>
                  My research interests are <b>computational imaging, medical imaging, machine learning, computer vision, inverse problems, optimization</b>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:weijie.gan@wustl.edu">Email</a> &nbsp/&nbsp
                  <!-- <a href="https://github.com/wjgancn">GitHub</a> &nbsp/&nbsp -->
                  <a href="https://wjgancn.github.io/files/CV.pdf">CV</a> &nbsp/&nbsp
                  <a href="https://www.linkedin.com/in/wjgancn/">Linkedin</a> &nbsp/&nbsp
                  <a href="https://twitter.com/WeijieGan1">Twitter</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?user=Ib20Ge0AAAAJ&hl=en">Google Scholar</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <img style="width:90%;max-width:90%" alt="profile photo" src="images/photo.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                2023/10: New preprint: <a href="https://arxiv.org/abs/2310.07504">PtychoDV: Vision Transformer-Based Deep Unrolling Network for Ptychographic Image Reconstruction</a>.
                <br>
                2023/10: New preprint: <a href="https://arxiv.org/abs/2310.04297">A Plug-and-PlayImage Registration Network</a>.
                <br>
                2023/09: Our BC-PnP paper got accepted to <a href="https://nips.cc/virtual/2023/poster/72086">NeurIPS 2023</a>.
                <br>
                2023/07: Our SelfDEQ paper got accepted to <a href="https://ieeexplore.ieee.org/abstract/document/10214618">IEEE TCI</a>.
                <br>
                2023/05: Excited to share that I will join <strong><a href="https://www.siemens-healthineers.com">Siemens Healthineers</a></strong>, Knoxville, TN, as a summer research intern in 2023, supervised by <a href="http://www.google.com">Dr. Jorge Cabello</a> and <a href="http://www.google.com">Dr. Maurizio Conti</a>.
                <br>
                2022/05: Excited to share that I will join <strong><a href="https://www.lanl.gov">Los Alamos National Lab (LANL)</a></strong>, Los Alamos, NM, as a summer research intern in 2022, supervised by <a href="http://brendt.wohlberg.net">Dr. Brendt Wohlberg</a>.
              </p>
            </td>
        </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Selected Research</heading>
                <p>My complete publications are available at <a href="https://scholar.google.com/citations?user=Ib20Ge0AAAAJ&hl=en">google scholar</a>. Representative papers are <span class="highlight">highlighted</span>. (* denotes co-first authors)</p>
              </td>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:40%;vertical-align:middle">
                  <div class="one">
                    <img src='images/2023_PtychoDV.png' height="90%">
                  </div>
                </td>

                <td style="padding:20px;width:60%;vertical-align:top">
                  <papertitle>PtychoDV: Vision Transformer-Based Deep Unrolling Network for Ptychographic Image Reconstruction</papertitle>
                 <br>
                 <strong>Weijie Gan</strong>, <a href="https://www.qiuchen-zhai.com">Qiuchen Zhai</a>, <a href="https://scholar.google.com/citations?user=TIGnz9EAAAAJ&hl=en">Michael Thompson McCann</a>, <a href="https://scholar.google.com/citations?user=WIxIUC4AAAAJ&hl=en">Cristina Garcia-Cardona</a>, <a href="https://engineering.wustl.edu/faculty/Ulugbek-Kamilov.html">Ulugbek Kamilov</a>, <a href="https://brendt.wohlberg.net">Brendt Wohlberg</a>
                 <br>
                 <em>arXiv, 2023</em>
                 <br>
                 <a href="https://arxiv.org/abs/2310.07504">arXiv</a>
                 <p>
                  We proposed a new ptychographic image reconstruction algorithm based on vision transformer and deep unfolding.
                 </p>
                 </td>
              </tr>
         </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:40%;vertical-align:middle">
                  <div class="one">
                    <img src='images/2023_PIRATE.gif' height="90%">
                  </div>
                </td>

                <td style="padding:20px;width:60%;vertical-align:top">
                  <papertitle>A Plug-and-Play Image Registration Network</papertitle>
                 <br>
                 <a href="https://scholar.google.com/citations?user=3uVGLb0AAAAJ&hl=zh-CN">Junhao Hu*</a>, <strong>Weijie Gan*</strong>, <a href="https://flora-sun-zhixin.github.io">Zhixin Sun</a>, <a href="https://www.mir.wustl.edu/employees/hongyu-an/">Hong An</a>, <a href="https://engineering.wustl.edu/faculty/Ulugbek-Kamilov.html">Ulugbek Kamilov</a>
                 <br>
                 <em>arXiv, 2023</em>
                 <br>
                 <a href="https://arxiv.org/abs/2310.04297">arXiv</a>
                 /
                 <a href="https://wustl-cig.github.io/pirate/">project page</a>
                 <p>
                  The first plug-and-play method for image registration that uses a pre-trained denoiser as the prior information.
                 </p>
                 </td>
              </tr>
         </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:40%;vertical-align:middle">
                  <div class="one">
                    <img src='images/2023_BCPnP.gif' height="90%">
                  </div>
                </td>

                <td style="padding:20px;width:60%;vertical-align:top">
                  <papertitle>Block Coordinate Plug-and-Play Methods for Blind Inverse Problems</papertitle>
                 <br>
                 <strong>Weijie Gan</strong>, <a href="https://shirinsg.github.io">Shirin Shoushtari</a>, <a href="https://hu-yuyang.github.io">Yuyang Hu</a>, <a href="https://jiamingliu-jeremy.github.io">Jiaming Liu</a>, <a href="https://www.mir.wustl.edu/employees/hongyu-an/">Hong An</a>, <a href="https://engineering.wustl.edu/faculty/Ulugbek-Kamilov.html">Ulugbek Kamilov</a>
                 <br>
                 <em>NeurIPS 2023</em>
                 <br>
                 <a href="https://arxiv.org/abs/2305.12672">arXiv</a>
                 /
                 <a href="https://nips.cc/virtual/2023/poster/72086">NeurIPS</a>
                 /
                 <a href="https://wustl-cig.github.io/bcpnpwww/">project page</a>
                 <p>
                  A block-coordinate PnP method with theoretical analysis for blind inverse problems.
                 </p>
                 </td>
              </tr>
         </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:40%;vertical-align:middle">
                  <div class="one">
                    <img src='images/2022_SelfDEQ.png' height="90%">
                  </div>
                </td>

                <td style="padding:20px;width:60%;vertical-align:top">
                  <papertitle>Self-Supervised Deep Equilibrium Models With Theoretical Guarantees and Applications to MRI Reconstruction</papertitle>
                 <br>
                 <strong>Weijie Gan</strong>, <a href="https://www.researchgate.net/profile/Chunwei_Ying">Chunwei Ying</a>,  <a href="https://www.linkedin.com/in/parna-eshraghi-249b20114/">Parna Eshraghi</a>, <a href="https://www.linkedin.com/in/cornelia-wang-744665118/">Tongyao Wang</a>, <a href="https://www.mir.wustl.edu/employees/cihat-eldeniz/">Cihat Eldeniz</a>, <a href="https://hu-yuyang.github.io">Yuyang Hu</a>, <a href="https://jiamingliu-jeremy.github.io">Jiaming Liu</a>, <a href="https://profiles.wustl.edu/en/persons/yasheng-chen">Yasheng Chen</a>, <a href="https://www.mir.wustl.edu/employees/hongyu-an/">Hong An</a>, <a href="https://engineering.wustl.edu/faculty/Ulugbek-Kamilov.html">Ulugbek Kamilov</a>
                 <br>
                 <em>IEEE Transactions on Computational Imaging, 2023</em>
                 <br>
                 <a href="https://arxiv.org/abs/2210.03837">arXiv</a> / <a href="https://ieeexplore.ieee.org/abstract/document/10214618">IEEE</a>
                 <p>
                  First to propose self-supervised learning for deep equilibrium model with theoretical guarantees.
                 </p>
                 </td>
              </tr>
        </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:40%;vertical-align:middle">
                  <div class="one">
                    <img src='images/2022_SPICE.gif' height="90%">
                  </div>
                </td>

                <td style="padding:20px;width:60%;vertical-align:top">
                  <papertitle>SPICE: Self-supervised learning for MRI with automatic coil sensitivity estimation</papertitle>
                 <br>
                 <a href="https://hu-yuyang.github.io">Yuyang Hu*</a>, <strong>Weijie Gan*</strong>, <a href="https://www.researchgate.net/profile/Chunwei_Ying">Chunwei Ying</a>, <a href="https://www.linkedin.com/in/cornelia-wang-744665118/">Tongyao Wang</a>, <a href="https://www.mir.wustl.edu/employees/cihat-eldeniz/">Cihat Eldeniz</a>, <a href="https://jiamingliu-jeremy.github.io">Jiaming Liu</a>, <a href="https://profiles.wustl.edu/en/persons/yasheng-chen">Yasheng Chen</a>, <a href="https://www.mir.wustl.edu/employees/hongyu-an/">Hong An</a>, <a href="https://engineering.wustl.edu/faculty/Ulugbek-Kamilov.html">Ulugbek Kamilov</a>
                 <br>
                 <em>arXiv, 2022</em>
                 <br>
                 <a href="https://arxiv.org/abs/2210.02584">arXiv</a>
                 /
                 <a href="https://wustl-cig.github.io/spicewww/">project page</a>
                 <p>
                  The first self-supervised method for automatic coil sensitivity calibration in MRI.
                 </p>
                 </td>
              </tr>
        </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:40%;vertical-align:middle">
                  <div class="one">
                    <img src='images/2022_DeCoLearn.gif' height="90%">
                  </div>
                </td>

                <td style="padding:20px;width:60%;vertical-align:top">
                  <papertitle>DeCoLearn: Deformation-compensated learning for image reconstruction without ground truth</papertitle>
                 <br>
                 <strong>Weijie Gan</strong>, <a href="https://sunyumark.github.io">Yu Sun</a>, <a href="https://www.mir.wustl.edu/employees/cihat-eldeniz/">Cihat Eldeniz</a>, <a href="https://jiamingliu-jeremy.github.io">Jiaming Liu</a>, <a href="https://www.mir.wustl.edu/employees/hongyu-an/">Hong An</a>, <a href="https://engineering.wustl.edu/faculty/Ulugbek-Kamilov.html">Ulugbek Kamilov</a>
                 <br>
                 <em>IEEE Transactions on Medical Imaging, 2022</em>
                 <br>
                 <a href="https://arxiv.org/abs/2107.05533">arXiv</a>
                 /
                 <a href="https://wustl-cig.github.io/decolearnwww/">project page</a>
                 <p>
                  Joint image reconstruction and image registration without any ground-truth supervision.
                 </p>
                 </td>
              </tr>
        </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:40%;vertical-align:middle">
                  <div class="one">
                    <img src='images/2022_CURE.gif' height="90%">
                  </div>
                </td>

                <td style="padding:20px;width:60%;vertical-align:top">
                  <papertitle>CURE: Learning Cross-Video Neural Representations for High-Quality Frame Interpolation</papertitle>
                 <br>
                 <a href="http://www.wshangguan.com">Wentao Shangguan</a>, <a href="https://sunyumark.github.io">Yu Sun</a>, <strong>Weijie Gan</strong>, <a href="https://engineering.wustl.edu/faculty/Ulugbek-Kamilov.html">Ulugbek Kamilov</a>
                 <br>
                 <em>ECCV, 2022</em>
                 <br>
                 <a href="https://arxiv.org/abs/2203.00137">arXiv</a>
                 /
                 <a href="http://cure.wshangguan.com">project page</a>
                 <p>
                  First to propose a video frame interpolation algorithm based on neural field that can achieve SOTA performance.
                 </p>
                 </td>
              </tr>
        </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:40%;vertical-align:middle">
                  <div class="one">
                    <img src='images/2021_P2P.png' height="90%">
                  </div>
                </td>

                <td style="padding:20px;width:60%;vertical-align:top">
                  <papertitle>Phase2Phase: Respiratory motion-resolved reconstruction of free-breathing magnetic resonance imaging using deep learning without a ground truth for improved liver imaging</papertitle>
                 <br>
                 <a href="https://www.mir.wustl.edu/employees/cihat-eldeniz/">Cihat Eldeniz*</a>, <strong>Weijie Gan*</strong>, Sihao Chen, Tyler J Fraum, Daniel R Ludwig, Yan Yan, <a href="https://jiamingliu-jeremy.github.io">Jiaming Liu</a>, Thomas Vahle, Uday Krishnamurthy, <a href="https://engineering.wustl.edu/faculty/Ulugbek-Kamilov.html">Ulugbek Kamilov</a>, <a href="https://www.mir.wustl.edu/employees/hongyu-an/">Hong An</a>
                 <br>
                 <em>Investigative Radiology, 2021</em>
                 <br>
                 <a href="https://journals.lww.com/investigativeradiology/Abstract/2021/12000/Phase2Phase__Respiratory_Motion_Resolved.4.aspx?context=FeaturedArticles&collectionId=6">paper</a>
                 /
                 <a href="https://engineering.wustl.edu/news/2021/New-deep-learning-method-boosts-MRI-results-without-requiring-clean-training-data.html">media converge</a>
                 <p>
                  Propose a new deep learning method to boost MRI results without requiring clean training data.
                 </p>
                 </td>
              </tr>
        </tbody></table>

         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <tr>
                 <td style="padding:20px;width:40%;vertical-align:middle">
                   <div class="one">
                     <img src='images/2020_RARE.gif' height="90%">
                   </div>
                 </td>

                 <td style="padding:20px;width:60%;vertical-align:top">
                   <papertitle>RARE: Image reconstruction using deep priors learned without groundtruth</papertitle>
                  <br>
                  <a href="https://jiamingliu-jeremy.github.io">Jiaming Liu</a>, <a href="https://sunyumark.github.io">Yu Sun</a>, <a href="https://www.mir.wustl.edu/employees/cihat-eldeniz/">Cihat Eldeniz</a>, <strong>Weijie Gan</strong>, <a href="https://www.mir.wustl.edu/employees/hongyu-an/">Hong An</a>, <a href="https://engineering.wustl.edu/faculty/Ulugbek-Kamilov.html">Ulugbek Kamilov</a>
                  <br>
                  <em>IEEE Journal of Selected Topics in Signal Processing, 2020</em>
                  <br>
                  <a href="https://arxiv.org/pdf/1912.05854">arXiv</a>
                  <p>
                    Exploit statistical priors specified by artifact-removing CNNs trained without groundtruth.
                  </p>
                  </td>
               </tr>
         </tbody></table>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Interesting Projects</heading>
      </td>
  </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:40%;vertical-align:top">
                <div class="one">
                  <video height=90% controls>
                    <source src="videos/v554Proj.mp4" type="video/mp4">
                  </video>
                </div>
              </td>

                <td style="padding:20px;width:60%;vertical-align:top">
                  <papertitle>Track Microtubule in Medical Scan Video</papertitle>
                    <br>
                    <em>CSE554 Geometric Computing for Biomedicine
                    , 2018Fall</em>
                    <br>
                    <a href="https://github.com/wjgancn/WashU/tree/master/cse554">GitHub</a>
                    <p>
                        Proposed method with practical GUI tool to detect and track single micro-tubule movement in scan video. The tools also record the growth of target microtubule during video.
                    </p>
                </td>
              </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
                  <td style="padding:20px;width:40%;vertical-align:top">
                    <div class="one">
                      <video height=90% controls>
                        <source src="videos/vFSKE.mp4" type="video/mp4">
                      </video>
                    </div>
                  </td>

                  <td style="padding:20px;width:60%;vertical-align:top">
                    <papertitle>The 11st National "NXP Cup" Smart Car Race Competition for College Students</papertitle>
                    <br>
                    <em>
                    Second Prize of South China University of Technology Division & Third Prize of the Southern China Division
                    , May.2015 – Aug. 2016</em>
                    <p>
                    Designed a an auto-run smart car, which could recognize a pure white road with black borders by a specifics cam-era(Linear CCD) captured only one-row data(single dimension).
                  </p>
                  </td>
                </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Template is from <a href="https://jonbarron.info">Here</a>.
                <br>
                </p>
              </td>
            </tr>
          </tbody></table>

        </td>
    </tr>
  </table>
</body>

</html>
  